{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eab786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import os\n",
    "\n",
    "from model import build_model\n",
    "from torchvision import transforms\n",
    "\n",
    "# Constants.\n",
    "DATA_PATH = '../input/test_images'\n",
    "IMAGE_SIZE = 224\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "# Class names.\n",
    "class_names = ['Bishop', 'King', 'Knight', 'Pawn', 'Queen', 'Rook']\n",
    "\n",
    "# Load the trained model.\n",
    "model = build_model(pretrained=False, fine_tune=False, num_classes=6)\n",
    "checkpoint = torch.load('../outputs/model_pretrained_True.pth', map_location=DEVICE)\n",
    "print('Loading trained model weights...')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Get all the test image paths.\n",
    "all_image_paths = glob.glob(f\"{DATA_PATH}/*\")\n",
    "# Iterate over all the images and do forward pass.\n",
    "for image_path in all_image_paths:\n",
    "    print(1)\n",
    "    # Get the ground truth class name from the image path.\n",
    "    gt_class_name = image_path.split(os.path.sep)[-1].split('.')[0]\n",
    "    # Read the image and create a copy.\n",
    "    image = cv2.imread(image_path)\n",
    "    orig_image = image.copy()\n",
    "\n",
    "    # Preprocess the image\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "    image = transform(image)\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    image = image.to(DEVICE)\n",
    "\n",
    "    # Forward pass throught the image.\n",
    "    outputs = model(image)\n",
    "    outputs = outputs.detach().numpy()\n",
    "    pred_class_name = class_names[np.argmax(outputs[0])]\n",
    "    print(f\"GT: {gt_class_name}, Pred: {pred_class_name.lower()}\")\n",
    "    # Annotate the image with ground truth.\n",
    "    cv2.putText(\n",
    "        orig_image, f\"GT: {gt_class_name}\",\n",
    "        (10, 25), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        1.0, (0, 255, 0), 2, lineType=cv2.LINE_AA\n",
    "    )\n",
    "    \n",
    "    # Annotate the image with prediction.\n",
    "    cv2.putText(\n",
    "        orig_image, f\"Pred: {pred_class_name.lower()}\",\n",
    "        (10, 55), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        1.0, (100, 100, 225), 2, lineType=cv2.LINE_AA\n",
    "    )\n",
    "    #cv2.ims('Result', orig_image)\n",
    "    #cv2.waitKey(0)\n",
    "    cv2.imwrite(f\"../outputs/{gt_class_name}.png\", orig_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f56b629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf0bcde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
